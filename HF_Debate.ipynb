{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehA5e8a/agent_debate_system/blob/main/HF_Debate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5vx6UuaBT3go",
        "outputId": "24baabeb-f25e-4db6-82f5-d2065a3cfe2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<6,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch streamlit huggingface_hub python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i04SlAzkWbYf",
        "outputId": "452985b3-3016-4ea5-9a92-8db468fe4ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ],
      "source": [
        "%%writefile .env\n",
        "HUGGINGFACE_API_TOKEN=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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1Zm3-doWfoR",
        "outputId": "873664c1-a799-4d74-9e17-0f496696f936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting debate_app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile debate_app.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJeevAhjUVkN",
        "outputId": "dd1defc0-a6ea-4a62-d826-877c6674afb1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-05 12:45:54.625 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.791 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-11-05 12:45:54.793 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.796 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.798 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.801 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.803 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.805 Session state does not function when running a script without `streamlit run`\n",
            "2024-11-05 12:45:54.806 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.808 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.809 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.811 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.813 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-11-05 12:45:54.814 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "from huggingface_hub import InferenceClient\n",
        "import time\n",
        "from typing import List, Dict\n",
        "import json\n",
        "\n",
        "class HFInferenceLLM:\n",
        "    def __init__(self, api_token):\n",
        "        self.client = InferenceClient(\n",
        "            model=\"HuggingFaceH4/zephyr-7b-beta\",\n",
        "            token=api_token\n",
        "        )\n",
        "\n",
        "    def __call__(self, prompt: str) -> str:\n",
        "        try:\n",
        "            response = self.client.text_generation(\n",
        "                prompt,\n",
        "                max_new_tokens=256,\n",
        "                temperature=0.7,\n",
        "                repetition_penalty=1.1\n",
        "            )\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error generating response: {str(e)}\")\n",
        "            return \"Error generating response\"\n",
        "\n",
        "class DebateAgent:\n",
        "    def __init__(self, name: str, stance: str, llm):\n",
        "        self.name = name\n",
        "        self.stance = stance\n",
        "        self.llm = llm\n",
        "\n",
        "    def generate_argument(self, topic: str, context: str = \"\") -> str:\n",
        "        prompt = f\"\"\"As a debater arguing {self.stance} on the topic \"{topic}\",\n",
        "        provide a clear, logical, and persuasive argument.\n",
        "\n",
        "        Previous context: {context}\n",
        "\n",
        "        Keep your response focused on the strongest points and maintain a respectful tone.\n",
        "        Provide specific examples or evidence to support your position.\n",
        "\n",
        "        Response:\"\"\"\n",
        "\n",
        "        return self.llm(prompt)\n",
        "\n",
        "class FactCheckerAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def check_facts(self, statement: str) -> str:\n",
        "        prompt = f\"\"\"As a fact-checker, analyze this statement:\n",
        "\n",
        "        Statement: {statement}\n",
        "\n",
        "        Provide:\n",
        "        1. Accuracy Rating (True/Partially True/False)\n",
        "        2. Brief explanation with specific points\n",
        "        3. Any important context or caveats\n",
        "\n",
        "        Keep your response concise but thorough.\"\"\"\n",
        "\n",
        "        return self.llm(prompt)\n",
        "\n",
        "class ModeratorAgent:\n",
        "    def __init__(self, llm):\n",
        "        self.llm = llm\n",
        "\n",
        "    def moderate(self, topic: str, stage: str) -> str:\n",
        "        prompt = f\"\"\"As a debate moderator discussing {topic}, provide a {stage} statement.\n",
        "        Be professional, concise, and maintain neutrality.\n",
        "        Focus on guiding the debate and ensuring fair discussion.\"\"\"\n",
        "\n",
        "        return self.llm(prompt)\n",
        "\n",
        "class DebateSystem:\n",
        "    def __init__(self, topic: str, llm):\n",
        "        self.topic = topic\n",
        "        self.debater_pro = DebateAgent(\"Proponent\", \"in favor of\", llm)\n",
        "        self.debater_con = DebateAgent(\"Opponent\", \"against\", llm)\n",
        "        self.fact_checker = FactCheckerAgent(llm)\n",
        "        self.moderator = ModeratorAgent(llm)\n",
        "        self.debate_log = []\n",
        "\n",
        "    def log_event(self, event_type: str, content: str):\n",
        "        self.debate_log.append({\n",
        "            'type': event_type,\n",
        "            'content': content,\n",
        "            'timestamp': time.time()\n",
        "        })\n",
        "\n",
        "    def run_debate_round(self) -> List[Dict]:\n",
        "        # Introduction\n",
        "        intro = self.moderator.moderate(self.topic, \"opening\")\n",
        "        self.log_event(\"MODERATOR\", intro)\n",
        "\n",
        "        # Opening statements\n",
        "        for debater in [self.debater_pro, self.debater_con]:\n",
        "            statement = debater.generate_argument(self.topic)\n",
        "            self.log_event(f\"{debater.name.upper()}\", statement)\n",
        "\n",
        "            fact_check = self.fact_checker.check_facts(statement)\n",
        "            self.log_event(\"FACT_CHECK\", fact_check)\n",
        "\n",
        "        # Rebuttals\n",
        "        for debater in [self.debater_pro, self.debater_con]:\n",
        "            # Get opponent's last argument\n",
        "            opponent_arg = self.debate_log[-3]['content'] if debater == self.debater_pro else self.debate_log[-1]['content']\n",
        "            rebuttal = debater.generate_argument(self.topic, context=opponent_arg)\n",
        "            self.log_event(f\"{debater.name.upper()}_REBUTTAL\", rebuttal)\n",
        "\n",
        "            fact_check = self.fact_checker.check_facts(rebuttal)\n",
        "            self.log_event(\"FACT_CHECK\", fact_check)\n",
        "\n",
        "        # Closing\n",
        "        closing = self.moderator.moderate(self.topic, \"closing\")\n",
        "        self.log_event(\"MODERATOR\", closing)\n",
        "\n",
        "        return self.debate_log\n",
        "\n",
        "def main():\n",
        "    st.title(\"AI Debate System (Using Zephyr-7B)\")\n",
        "\n",
        "    # Hugging Face API Token input\n",
        "    api_token = st.text_input(\n",
        "        \"Enter your Hugging Face API token:\",\n",
        "        type=\"password\",\n",
        "        help=\"Get your free token at https://huggingface.co/settings/tokens\"\n",
        "    )\n",
        "\n",
        "    if not api_token:\n",
        "        st.warning(\"Please enter your Hugging Face API token to continue\")\n",
        "        st.markdown(\"\"\"\n",
        "        To get your free API token:\n",
        "        1. Go to [Hugging Face](https://huggingface.co/join)\n",
        "        2. Create an account or sign in\n",
        "        3. Go to Settings → Access Tokens\n",
        "        4. Create a new token\n",
        "        \"\"\")\n",
        "        return\n",
        "\n",
        "    # Initialize LLM\n",
        "    if 'llm' not in st.session_state:\n",
        "        try:\n",
        "            st.session_state['llm'] = HFInferenceLLM(api_token)\n",
        "            st.success(\"Successfully connected to Zephyr-7B! 🎉\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error connecting to Hugging Face: {str(e)}\")\n",
        "            return\n",
        "\n",
        "    # Topic selection\n",
        "    topic_options = [\n",
        "        \"Should artificial intelligence be regulated?\",\n",
        "        \"Is universal basic income a good idea?\",\n",
        "        \"Should social media platforms be responsible for content moderation?\",\n",
        "        \"Custom topic\"\n",
        "    ]\n",
        "\n",
        "    topic_selection = st.selectbox(\"Select debate topic:\", topic_options)\n",
        "\n",
        "    if topic_selection == \"Custom topic\":\n",
        "        topic = st.text_input(\"Enter your custom topic:\")\n",
        "    else:\n",
        "        topic = topic_selection\n",
        "\n",
        "    # Debate format options\n",
        "    st.sidebar.title(\"Debate Settings\")\n",
        "    format_options = {\n",
        "        \"Quick\": \"Single round of arguments\",\n",
        "        \"Standard\": \"Opening statements and rebuttals\",\n",
        "        \"Extended\": \"Multiple rounds with cross-examination\"\n",
        "    }\n",
        "    debate_format = st.sidebar.selectbox(\"Select debate format:\", list(format_options.keys()))\n",
        "\n",
        "    if st.button(\"Start Debate\"):\n",
        "        if topic:\n",
        "            with st.spinner(\"Generating debate...\"):\n",
        "                try:\n",
        "                    debate = DebateSystem(topic, st.session_state['llm'])\n",
        "                    debate_log = debate.run_debate_round()\n",
        "\n",
        "                    # Display debate with improved formatting\n",
        "                    for event in debate_log:\n",
        "                        if event['type'] == \"MODERATOR\":\n",
        "                            st.write(\"🎙️ **Moderator:**\")\n",
        "                            st.markdown(event['content'])\n",
        "                        elif \"REBUTTAL\" in event['type']:\n",
        "                            st.write(f\"🔄 **{event['type'].replace('_REBUTTAL', '')} Rebuttal:**\")\n",
        "                            st.markdown(event['content'])\n",
        "                        elif event['type'] in [\"PROPONENT\", \"OPPONENT\"]:\n",
        "                            st.write(f\"🗣️ **{event['type']}:**\")\n",
        "                            st.markdown(event['content'])\n",
        "                        elif event['type'] == \"FACT_CHECK\":\n",
        "                            with st.expander(\"📋 Fact Check\"):\n",
        "                                st.markdown(event['content'])\n",
        "                        st.markdown(\"---\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    st.error(f\"An error occurred: {str(e)}\")\n",
        "        else:\n",
        "            st.warning(\"Please enter a debate topic\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4-d8HF8Upnn",
        "outputId": "c270780a-b7b0-4d53-d3a6-434dfa53d4d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K\u001b[?25h\n",
            "up to date, audited 23 packages in 603ms\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "your url is: https://shaky-loops-tap.loca.lt\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.72.215.253:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# 4. Fourth cell - Install localtunnel and run the app\n",
        "!npm install localtunnel\n",
        "!streamlit run debate_app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jgw5bT4Wmoh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoNoT/XzjlJsUALzoFU7im",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}